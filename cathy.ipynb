{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4926782-d00f-4d98-a16c-fd67f9cdd390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from aws\n",
    "\n",
    "import csv\n",
    "\n",
    "# read split csvs\n",
    "videos = []\n",
    "for file in [\"test.csv\", \"train.csv\", \"val.csv\"]:\n",
    "    with open(file, 'r') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        for row in csv_reader:\n",
    "            line = str(row).split(\" \")\n",
    "            path = \"/\".join(line[0].split(\"/\")[4:])\n",
    "            videos.append(path)\n",
    "\n",
    "# use aws cli to download videos\n",
    "for video in videos:\n",
    "    path = \"dataset/guesswhat/\" + \"/\".join(video.split(\"/\")[:-1])\n",
    "    !mkdir -p {path}\n",
    "    !aws s3api get-object --bucket headsup-du1r3b78fy --key {video} dataset/guesswhat/{video} > download.txt\n",
    "\n",
    "\n",
    "# reformat split csvs\n",
    "for file in [\"test.csv\", \"train.csv\", \"val.csv\"]:\n",
    "    with open(file, 'w') as f1:\n",
    "        with open(\"split/\"+file, 'r') as f2:\n",
    "            csv_reader = csv.reader(f2)\n",
    "            csv_writer = csv.writer(f1)\n",
    "            for row in csv_reader:\n",
    "                line = \"dataset/guesswhat/\" + \"/\".join(str(row)[:-2].split(\"/\")[4:])\n",
    "                f1.write(line + \"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be0d9d-7d8a-4e66-bbae-1023b2d4758d",
   "metadata": {},
   "source": [
    "To fine-tune the video foundation models, I used the code provided in the <a href=\"https://github.com/OpenGVLab/InternVideo/tree/main/InternVideo1/Pretrain/VideoMAE\">VideoMAE GitHub</a> and made a few changes to accomodate for the \"GuessWhat\" dataset and binary classification task. \n",
    "\n",
    "<img src=\"images/1.png\" alt=\"drawing\" width=\"500\"/>\n",
    "<img src=\"images/2.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "The remaining changes consisted of minor, one-line edits scattered throughout the python project. These modifications were to adjust various aspects, such as the number of frames, and to remove/rework code that was causing errors :o. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad967d-632c-4561-a3d3-ce06cf2c65f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample script to fine-tune model  \n",
    "# change model configuration for difference experiments\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Define paths and any environment variables first\n",
    "base_path='/home/cathyhou'\n",
    "\n",
    "OUTPUT_DIR=\"$base_path/InternVideo/InternVideo/InternVideo1/Pretrain/VideoMAE/outputs/test_model/tta_ft_k400_ft_ssbd\"\n",
    "DATA_PATH=\"$base_path/splits\"\n",
    "MODEL_PATH=\"$base_path/models/tta_ft_k400_ft_ssbd.pth\"\n",
    "\n",
    "export CUDA_LAUNCH_BLOCKING=1\n",
    "# Environment variables\n",
    "export MASTER_PORT=$((12000 + RANDOM % 20001))\n",
    "export OMP_NUM_THREADS=1\n",
    "export DS_BUILD_OPS=1\n",
    "\n",
    "# Execute the python script with necessary parameters using -u for unbuffered output\n",
    "python -u run_class_linear.py \\\n",
    "    --model vit_base_patch16_224 \\\n",
    "    --data_set GW \\\n",
    "    --nb_classes 2 \\\n",
    "    --data_path \"$DATA_PATH\" \\\n",
    "    --finetune \"$MODEL_PATH\" \\\n",
    "    --log_dir \"$OUTPUT_DIR\" \\\n",
    "    --output_dir \"$OUTPUT_DIR\" \\\n",
    "    --batch_size 8 \\\n",
    "    --input_size 224 \\\n",
    "    --short_side_size 224 \\\n",
    "    --save_ckpt_freq 10 \\\n",
    "    --num_frames 16 \\\n",
    "    --sampling_rate 8 \\\n",
    "    --opt adamw \\\n",
    "    --lr 1e-3 \\\n",
    "    --layer_decay 0.90 \\\n",
    "    --num_workers 1 \\\n",
    "    --opt_betas 0.9 0.999 \\\n",
    "    --weight_decay 0.05 \\\n",
    "    --epochs 10 \\\n",
    "    --drop_path 0.35 \\\n",
    "    --auto_resume \\\n",
    "    --test_num_segment 2 \\\n",
    "    --test_num_crop 3 \\\n",
    "    --dist_eval --enable_deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c837ecb8-89d5-4317-99fb-5304a064bf7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate results\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "csv_path = \"/home/cathyhou/splits/test.csv\"\n",
    "results_dir = \"/home/cathyhou/InternVideo/InternVideo/InternVideo1/Pretrain/VideoMAE/results\"\n",
    "\n",
    "# make dict {shortened path: full path}\n",
    "videos = {}\n",
    "for line in open(csv_path):\n",
    "    path = line.split()[0]\n",
    "    videos[\"/\".join(path.split(\"/\")[-2:]).split(\".\")[0]] = path\n",
    "       \n",
    "# generate results csv \n",
    "def compute_video(lst):\n",
    "    i, video_id, data, label = lst\n",
    "    feat = [x for x in data]\n",
    "    feat = np.mean(feat, axis=0)\n",
    "    pred = np.argmax(feat)\n",
    "    return [videos[video_id.strip()],label,pred]\n",
    "\n",
    "def generate_results(test_file, results_dir, results_filename): \n",
    "    dict_feats = {}\n",
    "    dict_label = {}\n",
    "    dict_pos = {}\n",
    "\n",
    "    lines = open(test_file, 'r').readlines()[1:]\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        name = line.split('[')[0]\n",
    "        label = line.split(']')[1].split(' ')[1]\n",
    "        chunk_nb = line.split(']')[1].split(' ')[2]\n",
    "        split_nb = line.split(']')[1].split(' ')[3]\n",
    "        data = np.fromstring(line.split('[')[1].split(']')[0],\n",
    "                             dtype=float,\n",
    "                             sep=',')\n",
    "        if not name in dict_feats:\n",
    "            dict_feats[name] = []\n",
    "            dict_label[name] = 0\n",
    "            dict_pos[name] = []\n",
    "        if chunk_nb + split_nb in dict_pos[name]:\n",
    "            continue\n",
    "        dict_feats[name].append(softmax(data))\n",
    "        dict_pos[name].append(chunk_nb + split_nb)\n",
    "        dict_label[name] = label\n",
    "\n",
    "    input_lst = []\n",
    "    print(len(dict_feats))\n",
    "    for i, item in enumerate(dict_feats):\n",
    "        input_lst.append([i, item, dict_feats[item], dict_label[item]])\n",
    "\n",
    "    with open(results_dir+results_filename, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        field = [\"Path\", \"True Label\", \"Predicted Label\"]\n",
    "        writer.writerow(field)\n",
    "        for input in input_lst:\n",
    "            writer.writerow(compute_video(input))\n",
    "            \n",
    "# get scores\n",
    "def get_scores(results_dir, results_filename):\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    for line in open(results_dir+results_filename).readlines()[1:]:\n",
    "        preds.append(int(line.split(\",\")[2]))\n",
    "        labels.append(int(line.split(\",\")[1]))\n",
    "\n",
    "    print(\"accuracy: \", accuracy_score(labels, preds))\n",
    "    print(\"precision: \", precision_score(labels, preds))\n",
    "    print(\"recall: \", recall_score(labels, preds))\n",
    "    print(\"f1 score: \", f1_score(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc7e48-43b4-4c4d-ae19-ed4ef27adb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sh exp1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cae4df2c-f82c-435f-85bf-5fcf74fba6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "accuracy:  0.7674418604651163\n",
      "precision:  0.8260869565217391\n",
      "recall:  0.76\n",
      "f1 score:  0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "results_filename = \"/exp1_ssbd.csv\"\n",
    "test_file = \"/home/cathyhou/InternVideo/InternVideo/InternVideo1/Pretrain/VideoMAE/outputs/exp1/tta_ft_k400_ft_ssbd/0.txt\"\n",
    "\n",
    "generate_results(test_file, results_dir, results_filename)\n",
    "get_scores(results_dir, results_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ac83b0-1f9e-4103-8e31-fe9d2c494396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "accuracy:  0.627906976744186\n",
      "precision:  0.6153846153846154\n",
      "recall:  0.96\n",
      "f1 score:  0.75\n"
     ]
    }
   ],
   "source": [
    "results_filename = \"/exp4_intern.csv\"\n",
    "test_file = \"/home/cathyhou/InternVideo/InternVideo/InternVideo1/Pretrain/VideoMAE/outputs/exp4/vit_b_hybrid_pt_800e/0.txt\"\n",
    "\n",
    "generate_results(test_file, results_dir, results_filename)\n",
    "get_scores(results_dir, results_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
